{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing and Cleaning"
      ],
      "metadata": {
        "id": "9RtzHH_hFjCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/titanic_data.csv')\n",
        "\n",
        "# Basic info\n",
        "print(df.info())\n",
        "print(df.describe())\n",
        "print(df.head())\n",
        "\n",
        "# Check for missing values\n",
        "print(df.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGgVY49CFoYP",
        "outputId": "b76fc07c-32c5-4217-bf05-9b9431e4cd3d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 889 entries, 0 to 888\n",
            "Data columns (total 15 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   survived     889 non-null    int64  \n",
            " 1   pclass       889 non-null    int64  \n",
            " 2   sex          889 non-null    object \n",
            " 3   age          713 non-null    float64\n",
            " 4   sibsp        889 non-null    int64  \n",
            " 5   parch        889 non-null    int64  \n",
            " 6   fare         889 non-null    float64\n",
            " 7   embarked     887 non-null    object \n",
            " 8   class        889 non-null    object \n",
            " 9   who          889 non-null    object \n",
            " 10  adult_male   889 non-null    bool   \n",
            " 11  deck         203 non-null    object \n",
            " 12  embark_town  887 non-null    object \n",
            " 13  alive        889 non-null    object \n",
            " 14  alone        889 non-null    bool   \n",
            "dtypes: bool(2), float64(2), int64(4), object(7)\n",
            "memory usage: 92.2+ KB\n",
            "None\n",
            "         survived      pclass         age       sibsp       parch        fare\n",
            "count  889.000000  889.000000  713.000000  889.000000  889.000000  889.000000\n",
            "mean     0.384702    2.307087   29.698696    0.523060    0.382452   32.259059\n",
            "std      0.486799    0.836367   14.536691    1.103729    0.806761   49.735870\n",
            "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
            "25%      0.000000    2.000000   20.000000    0.000000    0.000000    7.925000\n",
            "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
            "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
            "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200\n",
            "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
            "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
            "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
            "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
            "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
            "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
            "\n",
            "     who  adult_male deck  embark_town alive  alone  \n",
            "0    man        True  NaN  Southampton    no  False  \n",
            "1  woman       False    C    Cherbourg   yes  False  \n",
            "2  woman       False  NaN  Southampton   yes   True  \n",
            "3  woman       False    C  Southampton   yes  False  \n",
            "4    man        True  NaN  Southampton    no   True  \n",
            "survived         0\n",
            "pclass           0\n",
            "sex              0\n",
            "age            176\n",
            "sibsp            0\n",
            "parch            0\n",
            "fare             0\n",
            "embarked         2\n",
            "class            0\n",
            "who              0\n",
            "adult_male       0\n",
            "deck           686\n",
            "embark_town      2\n",
            "alive            0\n",
            "alone            0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing numerical values with mean/median\n",
        "# Imputing 'age' with the mean\n",
        "df['age'] = df['age'].fillna(df['age'].mean())\n",
        "\n",
        "# For categorical columns, fill with mode\n",
        "# Imputing 'embarked' with the mode\n",
        "df['embarked'] = df['embarked'].fillna(df['embarked'].mode()[0])\n",
        "# Imputing 'embark_town' with the mode\n",
        "df['embark_town'] = df['embark_town'].fillna(df['embark_town'].mode()[0])\n",
        "\n",
        "# Note: 'deck' has a large number of missing values.\n",
        "# You might choose to drop this column or handle it differently,\n",
        "# but if you wanted to fill it with the mode:\n",
        "# df['deck'] = df['deck'].fillna(df['deck'].mode()[0])\n",
        "\n",
        "# Check missing values again to confirm imputation\n",
        "print(\"\\nMissing values after imputation:\")\n",
        "print(df.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yX-K7zdXGB2C",
        "outputId": "3861c835-d4ad-450d-ac60-5493d979adbe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values after imputation:\n",
            "survived         0\n",
            "pclass           0\n",
            "sex              0\n",
            "age              0\n",
            "sibsp            0\n",
            "parch            0\n",
            "fare             0\n",
            "embarked         0\n",
            "class            0\n",
            "who              0\n",
            "adult_male       0\n",
            "deck           686\n",
            "embark_town      0\n",
            "alive            0\n",
            "alone            0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df['Sex'] = le.fit_transform(df['sex'])  # male:1, female:0\n",
        "\n",
        "# Check if 'embarked' column exists before one-hot encoding\n",
        "if 'embarked' in df.columns:\n",
        "    # One-hot encode 'embarked'\n",
        "    df = pd.get_dummies(df, columns=['embarked'], drop_first=True)\n",
        "else:\n",
        "    print(\"Error: 'embarked' column not found in the DataFrame. Cannot perform one-hot encoding.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m08Gl5-BHUj1",
        "outputId": "0d6c6895-bba7-4c82-df42-56c0fd0d564d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 'embarked' column not found in the DataFrame. Cannot perform one-hot encoding.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add this line to inspect columns\n",
        "print(\"\\nColumns before dropping:\")\n",
        "print(df.columns)\n",
        "\n",
        "# Not useful for prediction\n",
        "# Check if columns exist before dropping\n",
        "columns_to_drop = ['sex', 'fare', 'class']\n",
        "existing_columns_to_drop = [col for col in columns_to_drop if col in df.columns]\n",
        "\n",
        "if existing_columns_to_drop:\n",
        "    df = df.drop(columns=existing_columns_to_drop)\n",
        "    print(f\"\\nDropped columns: {existing_columns_to_drop}\")\n",
        "else:\n",
        "    print(\"\\nNone of the specified columns ('sex', 'fare', 'class') found in the DataFrame.\")\n",
        "\n",
        "# Optional: Print columns after dropping to confirm\n",
        "print(\"\\nColumns after dropping:\")\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knYjJdDwJnmC",
        "outputId": "98a149a9-a27d-4353-ad44-70f5675b335a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Columns before dropping:\n",
            "Index(['survived', 'pclass', 'sex', 'sibsp', 'parch', 'class', 'adult_male',\n",
            "       'deck', 'embark_town', 'alive', 'alone', 'Sex', 'embarked_Q',\n",
            "       'embarked_S'],\n",
            "      dtype='object')\n",
            "\n",
            "Dropped columns: ['sex', 'class']\n",
            "\n",
            "Columns after dropping:\n",
            "Index(['survived', 'pclass', 'sibsp', 'parch', 'adult_male', 'deck',\n",
            "       'embark_town', 'alive', 'alone', 'Sex', 'embarked_Q', 'embarked_S'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter the DataFrame to remove rows identified as outliers in any of the columns\n",
        "import numpy as np\n",
        "import pandas as pd # Ensure pandas is imported in this cell if it's the first one using it\n",
        "\n",
        "# Add this check to see the columns right before the error\n",
        "print(\"\\nColumns in df before outlier removal:\")\n",
        "print(df.columns)\n",
        "\n",
        "# --- Define outlier_conditions ---\n",
        "# This is a placeholder. You need to replace 'some_column' and 'some_condition'\n",
        "# with your actual outlier detection logic. For example, using IQR:\n",
        "\n",
        "# Check if 'age' column exists before proceeding\n",
        "if 'survived' in df.columns:\n",
        "    Q1 = df['survived'].quantile(0.25)\n",
        "    Q3 = df['survived'].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Example outlier condition for 'age'\n",
        "    outlier_conditions = (df['survived'] >= lower_bound) & (df['survived'] <= upper_bound)\n",
        "\n",
        "    # You would typically create outlier conditions for multiple numerical columns\n",
        "    # and combine them using the '&' operator if you want to keep rows that are\n",
        "    # NOT outliers in ANY of the specified columns.\n",
        "    # For example:\n",
        "    # numerical_cols = ['age', 'sibsp', 'parch'] # Add other numerical columns\n",
        "    # outlier_conditions = pd.Series([True] * len(df)) # Start with all True\n",
        "    # for col in numerical_cols:\n",
        "    #     if col in df.columns: # Add check for each column\n",
        "    #         Q1 = df[col].quantile(0.25)\n",
        "    #         Q3 = df[col].quantile(0.75)\n",
        "    #         IQR = Q3 - Q1\n",
        "    #         lower_bound = Q1 - 1.5 * IQR\n",
        "    #         upper_bound = Q3 + 1.5 * IQR\n",
        "    #         col_condition = (df[col] >= lower_bound) & (df[col] <= upper_bound)\n",
        "    #         outlier_conditions = outlier_conditions & col_condition\n",
        "    #     else:\n",
        "    #         print(f\"Warning: Column '{col}' not found for outlier detection.\")\n",
        "\n",
        "\n",
        "    # --- Apply the condition to create df_cleaned ---\n",
        "    df_cleaned = df[outlier_conditions]\n",
        "\n",
        "    # --- The original code below this line ---\n",
        "    # df = df_cleaned # This line is redundant if you continue using df_cleaned\n",
        "\n",
        "    print(f\"\\nDataFrame shape after outlier removal: {df_cleaned.shape}\")\n",
        "    print(f\"Number of rows removed: {df.shape[0] - df_cleaned.shape[0]}\")\n",
        "\n",
        "    # Now df_cleaned contains the data with outliers removed from the specified numerical columns\n",
        "    # You can continue using df_cleaned or assign it back to df if preferred:\n",
        "    #df = df_cleaned\n",
        "\n",
        "else:\n",
        "    print(\"Error: 'survived' column not found in the DataFrame. Cannot perform outlier removal based on 'age'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hw-9E4GBLqtW",
        "outputId": "42454623-2693-45bd-8d89-94574afc8973"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Columns in df before outlier removal:\n",
            "Index(['survived', 'pclass', 'sibsp', 'parch', 'adult_male', 'deck',\n",
            "       'embark_town', 'alive', 'alone', 'Sex', 'embarked_Q', 'embarked_S'],\n",
            "      dtype='object')\n",
            "\n",
            "DataFrame shape after outlier removal: (889, 12)\n",
            "Number of rows removed: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler # Import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "df[['survived', 'parch']] = scaler.fit_transform(df[['survived', 'parch']])\n"
      ],
      "metadata": {
        "id": "YzIgzhAJM6Hj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = df.drop('survived', axis=1)\n",
        "y = df['survived']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "zDu8I-FAOI7H"
      },
      "execution_count": 37,
      "outputs": []
    }
  ]
}